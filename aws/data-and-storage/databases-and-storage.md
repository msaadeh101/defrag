# AWS Data & Storage

## Databases


### Amazon RDS (Relational Database Service)

**RDS** is a Managed relational databases (`MySQL`, `PostgreSQL`, `MariaDB`, `Oracle`, `SQL Server`). Handles provisioning, backups, patching, snapshots, Multi-AZ failover.

**Use Cases**:
- Traditional relational schemas
- complex joins
- ACID transactions
- legacy DB engines.

#### Details

- **Connect** via standard JDBC drivers or use RDS IAM authentication to avoid embedded passwords. IAM auth uses tokens generated by the AWS SDK/CLI.

- For serverless/HTTP access to Aurora you can use the **RDS Data API** (executes SQL over HTTPS). Good for Lambda or services that can’t maintain persistent DB connections.

- **JDBC connection (MySQL)**:

```java
// Maven: include mysql-connector-java (or AWS JDBC wrapper)
String url = "jdbc:mysql://your-rds-endpoint:3306/mydb";
Properties props = new Properties();
props.setProperty("user", "dbuser");
props.setProperty("password", "secret");  // Replace with secrets management
try (Connection conn = DriverManager.getConnection(url, props)) {
    try (PreparedStatement p = conn.prepareStatement("SELECT id, name FROM users WHERE id=?")) {
        p.setInt(1, 1);
        try (ResultSet rs = p.executeQuery()) {
            if (rs.next()) System.out.println(rs.getString("name"));
        }
    }
}
```

B. **IAM auth token (RDS)**: generate token using AWS SDK v2.

```java
RdsUtilities util = RdsUtilities.builder().region(Region.of("us-east-1")).build();
String token = util.generateAuthenticationToken(GenerateAuthenticationTokenRequest.builder()
    .hostname("your-rds-endpoint").port(3306).username("dbuser").build());
// then use token as password; requires DB user to be created for IAM auth
```

### Amazon Aurora (MySQL/PostgreSQL-compatible cloud-native DB)

**Aurora** is a high-performance, highly-available relational DB compatible with `MySQL`/`Postgres`. Aurora Serverless v2 and provisioned clusters available. **Data API** available for HTTPS SQL execution against clusters.

**Use Cases**: 
- RDS compatibility with better scaling/perf
- Serverless v2 for variable workloads or when avoiding connection pooling is desirable

#### Details

**Aurora + Data API**: used for Lambda or microservices that avoid persistent connections; use RDS Data API client or SDK.

For heavy OLTP, choose provisioned Aurora with **connection pooling** (`HikariCP`, `ProxySQL`, or `RDS Proxy`).

- RDS Data API:

```java
RdsDataClient client = RdsDataClient.create();
ExecuteStatementRequest req = ExecuteStatementRequest.builder()
    .resourceArn("arn:aws:rds:...:cluster:your-cluster")
    .secretArn("arn:aws:secretsmanager:...:secret:yoursecret")
    .sql("SELECT id, name FROM users WHERE id=:id")
    .parameters(SqlParameter.builder().name("id").value(Field.builder().longValue(1L).build()).build())
    .database("mydb")
    .build();
ExecuteStatementResponse resp = client.executeStatement(req);
resp.records().forEach(record -> System.out.println(record));
```

### Amazon DynamoDB (NoSQL key-value & document store)

**DynamoDB** is a fully managed, *single-digit-ms latency*, serverless NoSQL DB. Strong/Eventually consistent reads, secondary indexes, TTL, DAX caching, global tables for multi-region replication. 

**Use Cases**:
- High-scale key-value/document workloads
- event storage
- session stores (serverless scaling)

#### Details

- Choose partition keys and sort keys carefully to **avoid hot partitions**.
- Use conditional writes, optimistic concurrency (`ConditionExpression`) for safe updates.
- For Java, prefer the AWS SDK v2 and DynamoDB Enhanced Client or Document API for a higher-level model. 
- SDK v2 Document API and Enhanced client

- PutItem (low-level)

```java
DynamoDbClient ddb = DynamoDbClient.create();
Map<String, AttributeValue> item = Map.of(
    "pk", AttributeValue.builder().s("user#1").build(),
    "name", AttributeValue.builder().s("Alice").build()
);
ddb.putItem(PutItemRequest.builder().tableName("Users").item(item).build());
```


- Enhanced client (POJO mapping):

```java
DynamoDbEnhancedClient enhanced = DynamoDbEnhancedClient.create();
DynamoDbTable<User> table = enhanced.table("Users", TableSchema.fromBean(User.class));
User u = new User("user#1","Alice");
table.putItem(u);
```

### Amazon DocumentDB (MongoDB-compatible)

**Amazon DocumentDB** is a fully managed, MongoDB-compatible document database designed for JSON workloads. It replicates the MongoDB 3.6/4.0/5.0 API (depending on cluster engine version) so applications using official MongoDB clients can connect with minimal/no code changes.

Use Cases:
- managed document database (JSON) at scale.
- Existing apps that use MongoDB drivers.
- need HA, automatic backups, and failover without self-managing MongoDB clusters.

#### Details

**Compatibility**: API-level compatibility, not wire-protocol-identical to upstream MongoDB internals. Avoid MongoDB features not yet supported (change streams, certain aggregation stages, transactions in older versions).

**Connections**:
- Use the standard MongoDB Java driver.
- Most deployments require TLS + SCRAM authentication.

**Networking**:
- Cluster runs inside a VPC; connect from EC2/EKS/Lambda with VPC access.
- DocumentDB requires TLS, and typically ?tls=true&tlsCAFile=rds-combined-ca-bundle.pem.

**Performance and Scaling**:
- Separation of compute and storage; storage auto-scales.
- Cluster volumes automatically replicate six copies across AZs.
- Add/remove read replicas to scale read traffic.
- Storage autoscaling is continuous; not provisioned like RDS.

- Basic MongoDB Java Driver Connection

```java
// DocumentDB uses standard MongoDB URI patterns.

import com.mongodb.client.*;
import org.bson.Document;

public class DocDbExample {
    public static void main(String[] args) {
        String uri = "mongodb://myuser:mypassword@" +
                "docdb-cluster.cluster-xxxxxxxxxxxx.us-east-1.docdb.amazonaws.com:27017" +
                "/?tls=true&replicaSet=rs0&readpreference=secondaryPreferred" +
                "&retryWrites=false";

        try (MongoClient client = MongoClients.create(uri)) {
            MongoDatabase db = client.getDatabase("mydb");
            MongoCollection<Document> col = db.getCollection("users");

            Document user = new Document("userId", "1").append("name", "Alice");
            col.insertOne(user);

            Document found = col.find(new Document("userId", "1")).first();
            System.out.println(found.toJson());
        }
    }
}
```

- `retryWrites=false` is required — DocumentDB does not support MongoDB retryable writes features.
- `readpreference=secondaryPreferred` is commonly used to offload reads.

- Connection with TLS CA Bundle (`rds-combined-ca-bundle.pem`)

```java
// If providing the CA file explicitly:
String uri = "mongodb://myuser:mypassword@" +
    "docdb-cluster.cluster-xxxxxx.us-east-1.docdb.amazonaws.com:27017" +
    "/?tls=true&tlsCAFile=/path/rds-combined-ca-bundle.pem&retryWrites=false";
MongoClient client = MongoClients.create(uri);
```

Download the CA from AWS:
- `https://truststore.pki.rds.amazonaws.com/global/global-bundle.pem`

- Using Connection Pool Settings (Best Practice Java)

```java
import com.mongodb.MongoClientSettings;
import com.mongodb.client.MongoClient;
import com.mongodb.client.MongoClients;
import javax.net.ssl.SSLContext;

MongoClientSettings settings = MongoClientSettings.builder()
        .applyConnectionString(new ConnectionString(
                "mongodb://myuser:mypassword@docdb-cluster.cluster-xxxxxx.us-east-1.docdb.amazonaws.com:27017" +
                "/?tls=true&retryWrites=false"
        ))
        .applyToConnectionPoolSettings(pool -> {
            pool.maxSize(50);
            pool.minSize(5);
            pool.maxConnecting(10);
        })
        .build();

MongoClient mongoClient = MongoClients.create(settings);
```

- DocumentDB fully supports the POJO codec registry used by the MongoDB Java driver.

```java
PojoCodecProvider pojoCodecProvider = PojoCodecProvider.builder().automatic(true).build();
CodecRegistry registry = fromRegistries(
        MongoClientSettings.getDefaultCodecRegistry(),
        fromProviders(pojoCodecProvider)
);

MongoDatabase db = mongoClient.getDatabase("mydb").withCodecRegistry(registry);
MongoCollection<User> users = db.getCollection("users", User.class);

// Insert
users.insertOne(new User("u123", "Alice"));

// Query
User u = users.find(eq("userId", "u123")).first();
```

**Migrations**: Use `mongodump` / `mongorestore` or **AWS Database Migration Service**.

## Storage

### Amazon S3 (Simple Storage Service)

**S3** is object storage for files, artifacts, backups, static website hosting. Infinite scale, lifecycle rules, versioning, encryption at rest (SSE-S3, SSE-KMS), pre-signed URLs. 

**Use Cases**: 
- Blobs
- logs
- backups
- static assets
- data lakes (with `Athena`/`Glue`).

#### Details

- Use multipart upload for large objects; enable lifecycle rules to transition to Glacier/IA for cost savings.
- Use SSE-KMS for envelope encryption with customer-managed keys.
- Use pre-signed URLs for temporary secure access.

- Upload small object

```java
S3Client s3 = S3Client.create();
PutObjectRequest req = PutObjectRequest.builder().bucket("my-bucket").key("path/to/file.txt").build();
s3.putObject(req, RequestBody.fromString("hello world"));
```

- Generate pre-signed URL

```java
S3Presigner presigner = S3Presigner.create();
PutObjectRequest por = PutObjectRequest.builder().bucket("my-bucket").key("upload.txt").build();
PutObjectPresignRequest presignRequest = PutObjectPresignRequest.builder()
    .signatureDuration(Duration.ofMinutes(15)).putObjectRequest(por).build();
PresignedPutObjectRequest pre = presigner.presignPutObject(presignRequest);
System.out.println(pre.url());
```

### EFS & FSx (File systems)

**EFS**: NFS-based, good for shared POSIX file system across EC2/EKS; scalability and bursting.

**FSx** (Lustre/Windows): High-performance file systems for HPC or Windows SMB workloads.

Use Java libraries and OS mounts when accessing file data (i.e., treat as POSIX filesystem rather than S3-style object access).
