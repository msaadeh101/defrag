AWS Data & Storage — Quick Wiki (Java-focused)
1) Amazon RDS (Relational Database Service)

What it is: Managed relational databases (MySQL, PostgreSQL, MariaDB, Oracle, SQL Server). Handles provisioning, backups, patching, snapshots, Multi-AZ failover. 
AWS Documentation

When to use: Traditional relational schemas, complex joins, ACID transactions, legacy DB engines.

Key details

Connect via standard JDBC drivers or use RDS IAM authentication to avoid embedded passwords. IAM auth uses tokens generated by the AWS SDK/CLI. 
AWS Documentation

For serverless/HTTP access to Aurora you can use the RDS Data API (executes SQL over HTTPS). Good for Lambda or services that can’t maintain persistent DB connections. 
AWS Documentation
+1

Java snippets

A. JDBC connection (MySQL) — simple example

// Maven: include mysql-connector-java (or AWS JDBC wrapper)
String url = "jdbc:mysql://your-rds-endpoint:3306/mydb";
Properties props = new Properties();
props.setProperty("user", "dbuser");
props.setProperty("password", "secret"); // prefer Secrets Manager or IAM token
try (Connection conn = DriverManager.getConnection(url, props)) {
    try (PreparedStatement p = conn.prepareStatement("SELECT id, name FROM users WHERE id=?")) {
        p.setInt(1, 1);
        try (ResultSet rs = p.executeQuery()) {
            if (rs.next()) System.out.println(rs.getString("name"));
        }
    }
}


B. IAM auth token (RDS) — generate token using AWS SDK v2

RdsUtilities util = RdsUtilities.builder().region(Region.of("us-east-1")).build();
String token = util.generateAuthenticationToken(GenerateAuthenticationTokenRequest.builder()
    .hostname("your-rds-endpoint").port(3306).username("dbuser").build());
// then use token as password; requires DB user to be created for IAM auth


(See AWS docs for setup steps: enable IAM auth, attach IAM policy, create DB user.) 
AWS Documentation

2) Amazon Aurora (MySQL/PostgreSQL-compatible cloud-native DB)

What it is: High-performance, highly-available relational DB compatible with MySQL/Postgres. Aurora Serverless v2 and provisioned clusters available. Data API available for HTTPS SQL execution against clusters. 
AWS Documentation
+1

When to use: When you need RDS compatibility with better scaling/perf; Serverless v2 for variable workloads or when avoiding connection pooling is desirable.

Key details

Aurora + Data API: great for Lambda or microservices that avoid persistent connections; use RDS Data API client or SDK. 
AWS Documentation
+1

For heavy OLTP, choose provisioned Aurora with connection pooling (HikariCP, ProxySQL, or RDS Proxy).

Java snippet — RDS Data API (AWS SDK v2)

RdsDataClient client = RdsDataClient.create();
ExecuteStatementRequest req = ExecuteStatementRequest.builder()
    .resourceArn("arn:aws:rds:...:cluster:your-cluster")
    .secretArn("arn:aws:secretsmanager:...:secret:yoursecret")
    .sql("SELECT id, name FROM users WHERE id=:id")
    .parameters(SqlParameter.builder().name("id").value(Field.builder().longValue(1L).build()).build())
    .database("mydb")
    .build();
ExecuteStatementResponse resp = client.executeStatement(req);
resp.records().forEach(record -> System.out.println(record));


(Enable Data API and set up Secrets Manager as the Data API credential source.) 
AWS Documentation
+1

3) Amazon DynamoDB (NoSQL key-value & document store)

What it is: Fully managed, single-digit-ms latency, serverless NoSQL DB. Strong/Eventually consistent reads, secondary indexes, TTL, DAX caching, global tables for multi-region replication. 
AWS Documentation
+1

When to use: High-scale key-value/document workloads, event storage, session stores, when you want serverless scaling.

Key details

Choose partition keys and sort keys carefully to avoid hot partitions.

Use conditional writes, optimistic concurrency (ConditionExpression) for safe updates.

For Java prefer the AWS SDK v2 and DynamoDB Enhanced Client or Document API for a higher-level model. 
AWS Documentation

Java snippets — SDK v2 (Document API and Enhanced client)

A. PutItem (low-level)

DynamoDbClient ddb = DynamoDbClient.create();
Map<String, AttributeValue> item = Map.of(
    "pk", AttributeValue.builder().s("user#1").build(),
    "name", AttributeValue.builder().s("Alice").build()
);
ddb.putItem(PutItemRequest.builder().tableName("Users").item(item).build());


B. Enhanced client (POJO mapping)

DynamoDbEnhancedClient enhanced = DynamoDbEnhancedClient.create();
DynamoDbTable<User> table = enhanced.table("Users", TableSchema.fromBean(User.class));
User u = new User("user#1","Alice");
table.putItem(u);

4) Amazon S3 (Simple Storage Service)

What it is: Object storage for files, artifacts, backups, static website hosting. Infinite scale, lifecycle rules, versioning, encryption at rest (SSE-S3, SSE-KMS), pre-signed URLs. 
AWS Documentation

When to use: Blobs, logs, backups, static assets, data lakes (with Athena/Glue).

Key details

Use multipart upload for large objects; enable lifecycle rules to transition to Glacier/IA for cost savings.

Use SSE-KMS for envelope encryption with customer-managed keys.

Use pre-signed URLs for temporary secure access.

Java snippets — AWS SDK v2

A. Upload small object

S3Client s3 = S3Client.create();
PutObjectRequest req = PutObjectRequest.builder().bucket("my-bucket").key("path/to/file.txt").build();
s3.putObject(req, RequestBody.fromString("hello world"));


B. Generate pre-signed URL

S3Presigner presigner = S3Presigner.create();
PutObjectRequest por = PutObjectRequest.builder().bucket("my-bucket").key("upload.txt").build();
PutObjectPresignRequest presignRequest = PutObjectPresignRequest.builder()
    .signatureDuration(Duration.ofMinutes(15)).putObjectRequest(por).build();
PresignedPutObjectRequest pre = presigner.presignPutObject(presignRequest);
System.out.println(pre.url());


(Refer to AWS Java SDK docs for multipart and transfer manager patterns.) 
AWS Documentation

5) EFS & FSx (File systems) — short notes

EFS: NFS-based, good for shared POSIX file system across EC2/EKS; scalability and bursting.

FSx (Lustre/Windows): High-performance file systems for HPC or Windows SMB workloads.

Use Java libraries and OS mounts when accessing file data (i.e., treat as POSIX filesystem rather than S3-style object access).

6) Secrets & Config (Parameter Store / Secrets Manager)

AWS Secrets Manager: rotate DB credentials, integrate with RDS/Aurora; Java SDK provides SecretsManagerClient to fetch secrets programmatically.

SSM Parameter Store: lower-cost config store; good for non-sensitive config or with KMS encryption for secure parameters.

Java snippet — get secret

SecretsManagerClient sm = SecretsManagerClient.create();
GetSecretValueResponse resp = sm.getSecretValue(GetSecretValueRequest.builder().secretId("my-secret").build());
String secret = resp.secretString();

Architecture & Operational tips (Java apps)

Credentials: Prefer IAM roles (EC2/EKS task role) over static keys; use DefaultCredentialsProvider in SDK v2.

Connection pooling: For RDS/Aurora use HikariCP + RDS Proxy for serverless/scale. For Aurora Serverless consider Data API to avoid connection pooling complexity. 
AWS Documentation

Retries & backoff: Use SDK retry policies; implement idempotency for writes (DynamoDB conditional writes; S3 multipart idempotency).

Local testing: Use DynamoDB Local / LocalStack for integration tests.

Secrets: Store DB passwords in Secrets Manager and reference by ARN (Data API uses Secret ARN). 
AWS Documentation

Further reading (official AWS docs)

RDS & Aurora Java examples and Data API: AWS Java SDK docs and RDS Data API guide. 
AWS Documentation
+1

DynamoDB Java docs (Document & Enhanced clients). 
AWS Documentation

S3 Java code examples (SDK v2)

Amazon DocumentDB (MongoDB-compatible)
What it is

Amazon DocumentDB is a fully managed, MongoDB-compatible document database designed for JSON workloads. It replicates the MongoDB 3.6/4.0/5.0 API (depending on cluster engine version) so applications using official MongoDB clients can connect with minimal/no code changes.

When to use

Use DocumentDB when:

You want a managed document database (JSON) at scale.

You already have apps that use MongoDB drivers.

You need HA, automatic backups, and failover without self-managing MongoDB clusters.

Key Details

Compatibility: API-level compatibility, not wire-protocol-identical to upstream MongoDB internals. Avoid MongoDB features not yet supported (change streams, certain aggregation stages, transactions in older versions).

Connections:

Use the standard MongoDB Java driver.

Most deployments require TLS + SCRAM authentication.

Networking:

Cluster runs inside a VPC; connect from EC2/EKS/Lambda with VPC access.

DocumentDB requires TLS, and typically ?tls=true&tlsCAFile=rds-combined-ca-bundle.pem.

Performance:

Separation of compute and storage; storage auto-scales.

Cluster volumes automatically replicate six copies across AZs.

Scaling:

Add/remove read replicas to scale read traffic.

Storage autoscaling is continuous; not provisioned like RDS.

Java Code — DocumentDB Connection Examples
1) Basic MongoDB Java Driver Connection

DocumentDB uses standard MongoDB URI patterns.

import com.mongodb.client.*;
import org.bson.Document;

public class DocDbExample {
    public static void main(String[] args) {
        String uri = "mongodb://myuser:mypassword@" +
                "docdb-cluster.cluster-xxxxxxxxxxxx.us-east-1.docdb.amazonaws.com:27017" +
                "/?tls=true&replicaSet=rs0&readpreference=secondaryPreferred" +
                "&retryWrites=false";

        try (MongoClient client = MongoClients.create(uri)) {
            MongoDatabase db = client.getDatabase("mydb");
            MongoCollection<Document> col = db.getCollection("users");

            Document user = new Document("userId", "1").append("name", "Alice");
            col.insertOne(user);

            Document found = col.find(new Document("userId", "1")).first();
            System.out.println(found.toJson());
        }
    }
}

Notes

retryWrites=false is required — DocumentDB does not support MongoDB retryable writes features.

readpreference=secondaryPreferred is commonly used to offload reads.

Use the rds-combined-ca-bundle.pem CA bundle.

2) Connection with TLS CA Bundle

If providing the CA file explicitly:

String uri = "mongodb://myuser:mypassword@" +
    "docdb-cluster.cluster-xxxxxx.us-east-1.docdb.amazonaws.com:27017" +
    "/?tls=true&tlsCAFile=/path/rds-combined-ca-bundle.pem&retryWrites=false";
MongoClient client = MongoClients.create(uri);


Download the CA from AWS:

https://truststore.pki.rds.amazonaws.com/global/global-bundle.pem

3) Using Connection Pool Settings (Recommended for Java Services)
import com.mongodb.MongoClientSettings;
import com.mongodb.client.MongoClient;
import com.mongodb.client.MongoClients;
import javax.net.ssl.SSLContext;

MongoClientSettings settings = MongoClientSettings.builder()
        .applyConnectionString(new ConnectionString(
                "mongodb://myuser:mypassword@docdb-cluster.cluster-xxxxxx.us-east-1.docdb.amazonaws.com:27017" +
                "/?tls=true&retryWrites=false"
        ))
        .applyToConnectionPoolSettings(pool -> {
            pool.maxSize(50);
            pool.minSize(5);
            pool.maxConnecting(10);
        })
        .build();

MongoClient mongoClient = MongoClients.create(settings);

4) POJO Mapping With the MongoDB Java Driver

DocumentDB fully supports the POJO codec registry used by the MongoDB Java driver.

PojoCodecProvider pojoCodecProvider = PojoCodecProvider.builder().automatic(true).build();
CodecRegistry registry = fromRegistries(
        MongoClientSettings.getDefaultCodecRegistry(),
        fromProviders(pojoCodecProvider)
);

MongoDatabase db = mongoClient.getDatabase("mydb").withCodecRegistry(registry);
MongoCollection<User> users = db.getCollection("users", User.class);

// Insert
users.insertOne(new User("u123", "Alice"));

// Query
User u = users.find(eq("userId", "u123")).first();

Operational Notes

Security:

Use AWS Secrets Manager to store MongoDB user passwords.

Attach IAM roles to EC2/ECS/EKS workloads.

Monitoring:

CloudWatch metrics: CPU, memory, IOPS, buffer cache hit ratio.

Event Notifications for failovers.

Backup & Restore:

Automated backups + point-in-time recovery (PITR).

Migrations:

Use mongodump / mongorestore or AWS Database Migration Service.